name: Agent Engine

# Make the run title human-readable in the Actions UI (avoid showing workflow file path strings).
run-name: >-
  Agent Engine • ${{ github.event_name }} • ${{ github.ref_name }} • run ${{ github.run_id }}

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      fault_scenario:
        description: 'Inject controlled E2E failure (selector|timeout|availability). Empty = normal run.'
        type: string
        required: false
        default: ''
      enable_public_tunnel:
        description: 'If true, start a public cloudflared tunnel on full success (manual runs only)'
        type: boolean
        required: false
        default: false

permissions:
  contents: read
  actions: read

concurrency:
  group: agent-engine-${{ github.run_id }}
  cancel-in-progress: true

jobs:
  auth-validator:
    name: Auth Validator
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: node scripts/agents/auth-validator.js
      upload_artifact_name: auth-validator-output
      upload_artifact_path: agent-outputs/auth-validator.json
      logs_artifact_name: backend-logs-auth-validator

  seed-orchestrator:
    name: Seed Orchestrator
    needs: auth-validator
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: bash -c "export SEED_COMMAND=\"python django/manage.py seed\" && node scripts/agents/seed-orchestrator.js" > agent-outputs/seed-orchestrator.json
      upload_artifact_name: seed-orchestrator-output
      upload_artifact_path: agent-outputs/seed-orchestrator.json
      logs_artifact_name: backend-logs-seed-orchestrator

  page-smoke:
    name: Page Smoke
    needs: seed-orchestrator
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: true
      agent_command: node scripts/agents/page-smoke.cjs > agent-outputs/page-smoke.json
      upload_artifact_name: page-smoke-output
      upload_artifact_path: agent-outputs/page-smoke.json
      logs_artifact_name: backend-logs-page-smoke

  env-doctor:
    name: Env Doctor
    needs: page-smoke
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: |
        mkdir -p agent-outputs
        python django/manage.py env_doctor --json > agent-outputs/env-doctor.json
      upload_artifact_name: env-doctor-output
      upload_artifact_path: agent-outputs/env-doctor.json
      logs_artifact_name: backend-logs-env-doctor

  db-doctor:
    name: DB Doctor
    needs: env-doctor
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: |
        mkdir -p agent-outputs
        python django/manage.py db_doctor --json > agent-outputs/db-doctor.json
      upload_artifact_name: db-doctor-output
      upload_artifact_path: agent-outputs/db-doctor.json
      logs_artifact_name: backend-logs-db-doctor

  patients-ui-smoke:
    name: Patients UI Smoke
    needs: db-doctor
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: |
        mkdir -p logs
        npx playwright test tests/e2e/patients-smoke.spec.ts --project=chromium 2>&1 | tee logs/patients-ui-smoke.log
      upload_artifact_name: patients-ui-smoke-results
      upload_artifact_path: |
        logs/patients-ui-smoke.log
        test-results/
      logs_artifact_name: backend-logs-patients-ui-smoke

  operations-ui-smoke:
    name: Operations UI Smoke
    needs: patients-ui-smoke
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: |
        mkdir -p logs
        npx playwright test tests/e2e/operations-smoke.spec.ts --project=chromium 2>&1 | tee logs/operations-ui-smoke.log
      upload_artifact_name: operations-ui-smoke-results
      upload_artifact_path: |
        logs/operations-ui-smoke.log
        test-results/
      logs_artifact_name: backend-logs-operations-ui-smoke

  availability-ui-smoke:
    name: Availability UI Smoke
    needs: operations-ui-smoke
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: |
        mkdir -p logs
        npx playwright test tests/e2e/appointments-availability-doctors.spec.ts --project=chromium 2>&1 | tee logs/availability-ui-smoke.log
      upload_artifact_name: availability-ui-smoke-results
      upload_artifact_path: |
        logs/availability-ui-smoke.log
        test-results/
      logs_artifact_name: backend-logs-availability-ui-smoke

  e2e-tests:
    name: E2E Tests
    needs: availability-ui-smoke
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: false
      agent_command: |
        mkdir -p logs
        FAULT_SCENARIO='${{ inputs.fault_scenario }}' npx playwright test 2>&1 | tee logs/playwright.log
      upload_artifact_name: test-results
      upload_artifact_path: |
        logs/playwright.log
        playwright-report/
        test-results/
      logs_artifact_name: backend-logs-e2e-tests

  startup-fix-agent:
    name: Startup Fix Agent (prepare self-heal context)
    needs: e2e-tests
    if: ${{ always() && github.event_name == 'workflow_dispatch' && needs.e2e-tests.result == 'failure' }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # NOTE: this job must not edit code; it only prepares structured context.
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'
          cache: 'npm'
      - name: Install Node dependencies
        run: npm ci

      - name: Download E2E artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: artifacts/e2e
      - name: Download backend logs
        uses: actions/download-artifact@v4
        with:
          name: backend-logs-e2e-tests
          path: artifacts/backend-logs

      - name: Prepare self-heal context
        # Integration point: collect logs and fetch Developer-Agent classification + self-heal plan.
        shell: bash
        env:
          AGENT_TOKEN: ${{ secrets.AGENT_TOKEN }}
          CLOUD_AGENT_URL: https://praxi-app.vercel.app/api/ci/logs
          E2E_STATUS: ${{ needs.e2e-tests.result }}
        run: |
          set -euo pipefail
          mkdir -p self-heal
          node tools/self-heal/prepare-context.mjs --out-dir self-heal

      - name: Ensure context exists
        if: ${{ always() }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p self-heal
          if [ ! -f self-heal/context.json ]; then
            echo '{"version":1,"error":"context_missing"}' > self-heal/context.json
          fi

      - name: Upload self-heal context
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: self-heal-context
          path: self-heal/context.json

  flaky-classifier:
    name: Flaky Classifier
    needs: e2e-tests
    if: ${{ always() }}
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: true
      agent_command: node scripts/agents/flaky-classifier.cjs > agent-outputs/flaky-classifier.json
      upload_artifact_name: flaky-classifier-output
      upload_artifact_path: agent-outputs/flaky-classifier.json
      logs_artifact_name: backend-logs-flaky-classifier

  selector-auditor:
    name: Selector Auditor
    needs: e2e-tests
    if: ${{ always() }}
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: true
      agent_command: node scripts/agents/selector-auditor.cjs > agent-outputs/selector-auditor.json
      upload_artifact_name: selector-auditor-output
      upload_artifact_path: agent-outputs/selector-auditor.json
      logs_artifact_name: backend-logs-selector-auditor

  fix-agent-supervisor:
    needs:
      - auth-validator
      - seed-orchestrator
      - page-smoke
      - e2e-tests
      - flaky-classifier
      - selector-auditor
      - self-heal-supervisor
    if: ${{ always() && (github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch') }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'
      - name: Download agent outputs
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: auth-validator-output
          path: agent-outputs
      - name: Download seed outputs
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: seed-orchestrator-output
          path: agent-outputs
      - name: Download smoke outputs
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: page-smoke-output
          path: agent-outputs
      - name: Download flaky outputs
        if: ${{ needs.flaky-classifier.result == 'success' }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: flaky-classifier-output
          path: agent-outputs
      - name: Download selector outputs
        if: ${{ needs.selector-auditor.result == 'success' }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: selector-auditor-output
          path: agent-outputs
      - name: Run supervisor
        run: |
          mkdir -p agent-outputs
          node scripts/agents/fix-agent-supervisor.cjs > agent-outputs/fix-agent-supervisor.json
      - name: Upload supervisor report
        uses: actions/upload-artifact@v4
        with:
          name: fix-agent-supervisor-output
          path: |
            agent-outputs/fix-agent-supervisor.json
            agent-outputs/supervisor-decision.json

  ci-dashboard-agent:
    needs:
      - auth-validator
      - seed-orchestrator
      - page-smoke
      - e2e-tests
      - flaky-classifier
      - selector-auditor
      - fix-agent-supervisor
      - self-heal-supervisor
    if: ${{ always() }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      SELF_HEAL_STATUS: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.self_heal_status || '' }}
      SELF_HEAL_CREATED_PR_NUMBER: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.created_pr_number || '' }}
      SELF_HEAL_ERROR_CLASSIFICATION: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.error_classification || '' }}
      SELF_HEAL_FIX_SUMMARY: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.fix_summary || '' }}
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'
      - name: Download agent outputs
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: auth-validator-output
          path: agent-outputs
      - name: Download seed outputs
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: seed-orchestrator-output
          path: agent-outputs
      - name: Download smoke outputs
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: page-smoke-output
          path: agent-outputs
      - name: Download flaky outputs
        if: ${{ needs.flaky-classifier.result == 'success' }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: flaky-classifier-output
          path: agent-outputs
      - name: Download selector outputs
        if: ${{ needs.selector-auditor.result == 'success' }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: selector-auditor-output
          path: agent-outputs
      - name: Download supervisor outputs
        if: ${{ needs.fix-agent-supervisor.result == 'success' }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: fix-agent-supervisor-output
          path: agent-outputs
      - name: Run ci-dashboard-agent
        run: |
          mkdir -p agent-outputs
          node scripts/agents/ci-dashboard-agent.js > agent-outputs/ci-dashboard-agent.json
      - name: Upload dashboard artifact
        uses: actions/upload-artifact@v4
        with:
          name: dashboard
          path: artifacts/dashboard/
      - name: Upload dashboard agent output
        uses: actions/upload-artifact@v4
        with:
          name: ci-dashboard-agent-output
          path: agent-outputs/ci-dashboard-agent.json

  publish-dashboard:
    needs:
      - ci-dashboard-agent
      - self-heal-supervisor
    if: ${{ always() }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: read
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    env:
      SELF_HEAL_STATUS: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.self_heal_status || '' }}
      SELF_HEAL_CREATED_PR_NUMBER: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.created_pr_number || '' }}
      SELF_HEAL_ERROR_CLASSIFICATION: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.error_classification || '' }}
      SELF_HEAL_FIX_SUMMARY: ${{ needs.self-heal-supervisor.result == 'success' && needs.self-heal-supervisor.outputs.fix_summary || '' }}
    steps:
      - uses: actions/checkout@v4
      - name: Download dashboard artifact
        # Best-effort: if dashboard wasn't produced, skip publishing without failing the workflow.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: dashboard
          path: public

      - name: Check dashboard presence
        id: has_dashboard
        shell: bash
        run: |
          set -euo pipefail
          if [ -f public/dashboard.html ]; then
            echo "has_dashboard=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_dashboard=false" >> "$GITHUB_OUTPUT"
            echo "No dashboard artifact found; skipping Pages publish."
          fi
      - name: Check whether GitHub Pages is enabled
        id: pages
        uses: actions/github-script@v7
        with:
          script: |
            try {
              await github.request('GET /repos/{owner}/{repo}/pages', {
                owner: context.repo.owner,
                repo: context.repo.repo,
              });
              core.setOutput('enabled', 'true');
            } catch (e) {
              if (e.status === 404) {
                core.setOutput('enabled', 'false');
                return;
              }
              throw e;
            }
      - name: Configure GitHub Pages
        if: steps.pages.outputs.enabled == 'true' && steps.has_dashboard.outputs.has_dashboard == 'true'
        uses: actions/configure-pages@v5
      - name: Upload to GitHub Pages artifact
        if: steps.pages.outputs.enabled == 'true' && steps.has_dashboard.outputs.has_dashboard == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: public
      - name: Deploy to GitHub Pages
        if: steps.pages.outputs.enabled == 'true' && steps.has_dashboard.outputs.has_dashboard == 'true'
        id: deployment
        uses: actions/deploy-pages@v4
      - name: Skip Pages deploy (no dashboard)
        if: steps.has_dashboard.outputs.has_dashboard != 'true'
        run: |
          echo "No dashboard to publish."
      - name: Skip Pages deploy (not enabled)
        if: steps.pages.outputs.enabled != 'true' && steps.has_dashboard.outputs.has_dashboard == 'true'
        run: |
          echo "GitHub Pages is not enabled for this repository."
          echo "Enable it at: https://github.com/${{ github.repository }}/settings/pages"

  post-dashboard-comment:
    runs-on: ubuntu-latest
    needs: publish-dashboard
    if: ${{ github.event_name == 'pull_request' && always() }}
    timeout-minutes: 30
    permissions:
      pull-requests: write
    steps:
      - uses: actions/checkout@v4
      - name: Download supervisor decision
        # Best-effort: avoid noise failures when supervisor output artifact is missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: fix-agent-supervisor-output
          path: agent-outputs

      - name: Ensure supervisor decision exists
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p agent-outputs
          if [ ! -f agent-outputs/supervisor-decision.json ]; then
            echo '{"decision":"n/a","dashboardUrl":"","reason":"missing supervisor decision artifact"}' > agent-outputs/supervisor-decision.json
          fi
      - name: Read supervisor decision
        run: cat agent-outputs/supervisor-decision.json
      - name: Post PR comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const decision = JSON.parse(fs.readFileSync('agent-outputs/supervisor-decision.json', 'utf8'));
            const url = decision.dashboardUrl || '(no dashboard url)';
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `**Agent Dashboard**\n\nDashboard: ${url}\n\nDecision: ${decision.decision || 'n/a'}`
            });

  self-heal-supervisor:
    name: Self-heal Supervisor (coordinate self-heal)
    needs: startup-fix-agent
    if: ${{ github.event_name == 'workflow_dispatch' && always() && needs.startup-fix-agent.result != 'skipped' }}
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      self_heal_status: ${{ steps.self_heal_status.outputs.self_heal_status }}
      should_self_heal: ${{ steps.decide.outputs.should_self_heal }}
      # Compatibility: downstream jobs expect this output to exist.
      created_pr_number: ${{ steps.compat.outputs.created_pr_number }}
      error_classification: ${{ steps.decide.outputs.error_classification }}
      fix_summary: ${{ steps.decide.outputs.fix_summary }}
    permissions:
      contents: read
    env:
      GITHUB_TOKEN: ${{ github.token }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'
          cache: 'npm'
      - name: Install Node dependencies
        run: npm ci

      - name: Download self-heal context
        # Integration point: consume prepared context from startup-fix-agent.
        uses: actions/download-artifact@v4
        with:
          name: self-heal-context
          path: .

      - name: Decide self-heal actions
        # Integration point: enforce guardrails (eligible error types only, rerun-only policy).
        id: decide
        shell: bash
        run: |
          set -euo pipefail
          node tools/self-heal/decide.mjs --context self-heal/context.json --out self-heal/decision.json
          should=$(node -e "const j=require('./self-heal/decision.json'); process.stdout.write(String(!!j.allowed));")
          classification=$(node -e "const j=require('./self-heal/decision.json'); process.stdout.write(String(j.error_type||''));")
          summary=$(node -e "const j=require('./self-heal/decision.json'); process.stdout.write(String(j.reason||''));")
          echo "should_self_heal=${should}" >> "$GITHUB_OUTPUT"
          echo "error_classification=${classification}" >> "$GITHUB_OUTPUT"
          echo "fix_summary<<EOF" >> "$GITHUB_OUTPUT"
          echo "${summary}" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

      - name: Upload self-heal decision
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: self-heal-decision
          path: self-heal/decision.json

      - name: Upload self-heal bundle
        # Integration point: bundle context+decision for the self-heal runner.
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: self-heal-bundle
          path: |
            self-heal/context.json
            self-heal/decision.json

      - name: Compatibility outputs
        id: compat
        shell: bash
        run: |
          set -euo pipefail
          echo "created_pr_number=" >> "$GITHUB_OUTPUT"

      - name: Set self-heal status output
        id: self_heal_status
        shell: bash
        run: |
          set -euo pipefail
          if [ "${{ steps.decide.outputs.should_self_heal }}" = "true" ]; then
            status="planned"
          else
            status="skipped"
          fi
          echo "self_heal_status=$status" >> "$GITHUB_OUTPUT"

  self-heal-runner:
    name: Self-heal Runner (safe rerun)
    needs:
      - auth-validator
      - self-heal-supervisor
    if: ${{ github.event_name == 'workflow_dispatch' && always() && needs.self-heal-supervisor.outputs.should_self_heal == 'true' }}
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: true
      # Integration point: run safe self-heal actions (no code edits) and upload a report artifact.
      agent_command: |
        mkdir -p self-heal
        node tools/self-heal/execute.mjs --context self-heal/context.json --decision self-heal/decision.json
      download_extra_artifact_name: self-heal-bundle
      download_extra_artifact_path: .
      upload_artifact_name: self-heal-report
      upload_artifact_path: |
        self-heal/report-${{ github.run_id }}.json
        self-heal/playwright-rerun.log
        self-heal/reseed.log
        self-heal/auth-validator.log
        self-heal/decision.json
        self-heal/context.json
      logs_artifact_name: backend-logs-self-heal

  fix-agent-prep:
    name: Fix-Agent Prep (build patch input)
    needs:
      - e2e-tests
      - self-heal-runner
    if: ${{ always() && needs.e2e-tests.result == 'failure' }}
    runs-on: ubuntu-latest
    timeout-minutes: 15
    # NOTE: best-effort: failures here must not flip the overall CI signal.
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'
          cache: 'npm'
      - name: Install Node dependencies
        run: npm ci

      - name: Download E2E artifacts
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: artifacts/e2e
      - name: Download backend logs
        # Best-effort: avoid noise failures when upstream artifacts are missing.
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: backend-logs-e2e-tests
          path: artifacts/backend-logs

      - name: Prepare Fix-Agent input
        # Integration point: fetch Developer-Agent fix instructions (via Cloud-Agent) and persist a stable input.json.
        shell: bash
        env:
          AGENT_TOKEN: ${{ secrets.AGENT_TOKEN }}
          CLOUD_AGENT_URL: https://praxi-app.vercel.app/api/ci/logs
          E2E_STATUS: ${{ needs.e2e-tests.result }}
        run: |
          set -euo pipefail
          mkdir -p fix-agent
          node tools/fix-agent/prepare-input.mjs --out-dir fix-agent --out fix-agent/input.json

      - name: Ensure Fix-Agent input exists
        if: ${{ always() }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p fix-agent
          if [ ! -f fix-agent/input.json ]; then
            echo '{"version":1,"error":"input_missing"}' > fix-agent/input.json
          fi

      - name: Upload Fix-Agent input
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: fix-agent-input
          path: fix-agent/input.json

  fix-agent-runner:
    name: Fix-Agent Runner (prepare patch)
    needs:
      - auth-validator
      - e2e-tests
      - fix-agent-prep
    if: ${{ always() && needs.e2e-tests.result == 'failure' && needs.fix-agent-prep.result != 'skipped' }}
    uses: ./.github/workflows/backend-setup.yml
    with:
      generate_storage_state: true
      # Integration point: scoped, guarded code changes only; emit patch + metadata artifacts (no PR creation).
      best_effort: true
      agent_command: |
        mkdir -p fix-agent
        node tools/fix-agent/apply-and-validate.mjs --input fix-agent/input.json --out-dir fix-agent
      download_extra_artifact_name: fix-agent-input
      download_extra_artifact_path: .
      upload_artifact_name: fix-agent-output
      upload_artifact_path: |
        fix-agent/patch-${{ github.run_id }}.diff
        fix-agent/metadata-${{ github.run_id }}.json
      logs_artifact_name: backend-logs-fix-agent

  create-fix-pr:
    name: Create Fix PR (Stage 2)
    needs:
      - fix-agent-runner
    if: ${{ always() && needs.fix-agent-runner.result == 'success' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: write
      pull-requests: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'
          cache: 'npm'

      - name: Install Node dependencies
        run: npm ci

      - name: Download fix-agent output
        uses: actions/download-artifact@v4
        with:
          name: fix-agent-output
          path: fix-agent

      - name: Extract metadata
        id: metadata
        shell: bash
        run: |
          set -euo pipefail
          
          # Find metadata file
          METADATA_FILE=$(find fix-agent -name "metadata-*.json" | head -n 1)
          
          if [ -z "$METADATA_FILE" ]; then
            echo "Metadata file not found"
            echo "skip=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "metadata_file=$METADATA_FILE" >> $GITHUB_OUTPUT
          
          # Extract key values
          RISK_LEVEL=$(jq -r '.risk_assessment.level // "unknown"' "$METADATA_FILE")
          AUTO_MERGE=$(jq -r '.risk_assessment.auto_merge_eligible // false' "$METADATA_FILE")
          NEEDS_REVIEW=$(jq -r '.needs_manual_review // true' "$METADATA_FILE")
          
          echo "risk_level=$RISK_LEVEL" >> $GITHUB_OUTPUT
          echo "auto_merge_eligible=$AUTO_MERGE" >> $GITHUB_OUTPUT
          echo "needs_manual_review=$NEEDS_REVIEW" >> $GITHUB_OUTPUT
          
          # Skip PR if needs manual review
          if [ "$NEEDS_REVIEW" = "true" ]; then
            echo "Manual review required, skipping PR creation"
            echo "skip=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "skip=false" >> $GITHUB_OUTPUT

      - name: Create and push fix branch
        if: ${{ steps.metadata.outputs.skip != 'true' }}
        shell: bash
        env:
          RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail
          
          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Find patch file
          PATCH_FILE=$(find fix-agent -name "patch-*.diff" | head -n 1)
          
          if [ -z "$PATCH_FILE" ]; then
            echo "Patch file not found"
            exit 1
          fi
          
          # Check if patch is empty
          if [ ! -s "$PATCH_FILE" ]; then
            echo "Patch file is empty, nothing to apply"
            exit 0
          fi
          
          # Create branch name
          ERROR_TYPE=$(jq -r '.error_type // "unknown"' "${{ steps.metadata.outputs.metadata_file }}")
          BRANCH_NAME="fix-agent/run-${RUN_ID}-${ERROR_TYPE}"
          
          # Create and checkout branch
          git checkout -b "$BRANCH_NAME"
          
          # Apply patch
          git apply "$PATCH_FILE"
          
          # Stage and commit
          git add -A
          git commit -m "fix(${ERROR_TYPE}): automated patch for CI run ${RUN_ID}"
          
          # Push branch
          git push origin "$BRANCH_NAME"
          
          echo "branch_name=$BRANCH_NAME" >> $GITHUB_ENV

      - name: Create Pull Request
        if: ${{ steps.metadata.outputs.skip != 'true' && env.branch_name != '' }}
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH_NAME: ${{ env.branch_name }}
          BASE_BRANCH: ${{ github.ref_name }}
          RISK_LEVEL: ${{ steps.metadata.outputs.risk_level }}
          AUTO_MERGE: ${{ steps.metadata.outputs.auto_merge_eligible }}
          RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail
          
          # Create PR body
          PR_BODY=$(cat <<EOF
          Automated Fix-Agent patch for run_id=${RUN_ID}.
          
          **Stage 2 - Conditional Autonomy**
          
          - Risk Level: \`${RISK_LEVEL}\`
          - Auto-merge Eligible: \`${AUTO_MERGE}\`
          - Guardrails: scoped changes only; capped file/line changes
          - Validation: minimal subset when possible
          
          This PR was automatically created by the Fix-Agent based on CI failure analysis.
          Please review carefully before merging.
          EOF
          )
          
          # Create PR using GitHub CLI
          if ! gh pr create \
            --base "${BASE_BRANCH}" \
            --head "${BRANCH_NAME}" \
            --title "fix: automated CI stabilization for run ${RUN_ID}" \
            --body "${PR_BODY}" \
            --label "automated-fix" \
            --label "${RISK_LEVEL}-risk"; then
            echo "⚠️  Failed to create PR (may already exist, permissions issue, or network error)"
            echo "Branch ${BRANCH_NAME} has been pushed and is available for manual PR creation"
          fi

  public-dashboard-access:
    name: Public Dashboard Access (cloudflared)
    needs:
      # Tight success semantics: only depend on the critical chain + dashboard publish.
      - auth-validator
      - seed-orchestrator
      - page-smoke
      - e2e-tests
      - ci-dashboard-agent
      - publish-dashboard
    # Safety: only allow the public tunnel on explicit manual intent.
    if: ${{ success() && github.event_name == 'workflow_dispatch' && inputs.enable_public_tunnel }}
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      POSTGRES_DB: praxiapp_system
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_HOST: 127.0.0.1
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: ${{ env.POSTGRES_DB }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
        ports:
          - 5432
        options: >-
          --health-cmd="pg_isready -h 127.0.0.1 -U postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=30
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Python dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure Postgres env
        shell: bash
        run: |
          set -euo pipefail
          echo "POSTGRES_PORT=${{ job.services.postgres.ports[5432] }}" >> "$GITHUB_ENV"
          echo "DATABASE_URL=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${{ job.services.postgres.ports[5432] }}/${POSTGRES_DB}" >> "$GITHUB_ENV"

      - name: Wait for Postgres
        shell: bash
        run: |
          set -euo pipefail
          echo "Waiting for Postgres to accept connections..."
          ready=false
          for i in {1..90}; do
            if pg_isready -h "${POSTGRES_HOST}" -p "${POSTGRES_PORT}" -U "${POSTGRES_USER}" >/dev/null 2>&1; then
              ready=true
              echo "Postgres is ready after ${i}s"
              break
            fi
            sleep 1
          done
          if [ "$ready" != "true" ]; then
            echo "Postgres not ready after 90 seconds" >&2
            exit 1
          fi

      - name: Apply migrations
        shell: bash
        run: |
          set -euo pipefail
          python django/manage.py migrate

      - name: Seed the database
        shell: bash
        run: |
          set -euo pipefail
          python django/manage.py seed

      - name: Ensure doctor exists
        shell: bash
        run: |
          set -euo pipefail
          python django/manage.py shell -c "
          from django.contrib.auth import get_user_model;
          from praxi_backend.core.models import Role;

          User = get_user_model();
          doctor_role, _ = Role.objects.get_or_create(name='doctor', defaults={'label': 'Arzt'});

          qs = User.objects.filter(is_active=True, role=doctor_role);
          if qs.exists():
              print(f'✅ Doctors present: {qs.count()}');
          else:
              u = User.objects.create_user('e2e_doctor', 'e2e_doctor@seed.local', 'test1234', first_name='E2E', last_name='Doctor');
              u.role = doctor_role;
              u.is_staff = True;
              u.save();
              print('✅ Created fallback doctor user');
          "

      - name: Start Django server
        shell: bash
        run: |
          set -euo pipefail
          nohup python django/manage.py runserver 0.0.0.0:8000 > django-server.log 2>&1 &

      - name: Wait for Django port
        shell: bash
        run: |
          set -euo pipefail
          echo "Waiting for Django (port 8000)..."
          ready=false
          for i in {1..60}; do
            if curl -fsS http://127.0.0.1:8000/api/health/ >/dev/null 2>&1; then
              ready=true
              echo "Django is reachable after ${i}s"
              break
            fi
            sleep 1
          done
          if [ "$ready" != "true" ]; then
            echo "Django did not become reachable within 60 seconds" >&2
            exit 1
          fi

      - name: Install cloudflared
        # Security: pin and verify cloudflared instead of downloading an unpinned "latest" binary.
        shell: bash
        run: |
          set -euo pipefail
          CLOUDFLARED_VERSION="2026.2.0"
          CLOUDFLARED_SHA256="176746db3be7dc7bd48f3dd287c8930a4645ebb6e6700f883fddda5a4c307c16"
          curl -L -o cloudflared "https://github.com/cloudflare/cloudflared/releases/download/${CLOUDFLARED_VERSION}/cloudflared-linux-amd64"
          echo "${CLOUDFLARED_SHA256}  cloudflared" | sha256sum -c -
          chmod +x cloudflared

      - name: Start public tunnel
        shell: bash
        run: |
          set -euo pipefail
          ./cloudflared tunnel --url http://localhost:8000 --no-autoupdate > tunnel.log 2>&1 &

      - name: Extract and print public URL
        shell: bash
        run: |
          set -euo pipefail
          echo "Waiting for trycloudflare URL..."
          url=""
          for i in {1..60}; do
            url=$(grep -oE 'https://[-a-z0-9]+\.trycloudflare\.com' tunnel.log | head -n 1 || true)
            if [ -n "$url" ]; then
              break
            fi
            sleep 1
          done
          if [ -z "$url" ]; then
            echo "No trycloudflare URL found in tunnel.log" >&2
            exit 1
          fi
          echo "${url}/admin/login/?next=/praxi_backend/Dashboardadministration/"

  send-ci-logs:
    name: Send CI logs to Developer-Agent
    needs:
      - auth-validator
      - seed-orchestrator
      - page-smoke
      - e2e-tests
      - startup-fix-agent
      - flaky-classifier
      - selector-auditor
      - self-heal-supervisor
      - fix-agent-supervisor
      - ci-dashboard-agent
      - publish-dashboard
      - post-dashboard-comment
      - public-dashboard-access
    if: ${{ always() }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Check artifact availability
        id: artifacts
        shell: bash
        env:
          GITHUB_TOKEN: ${{ github.token }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import json
          import os
          import urllib.request

          repo = os.environ["GITHUB_REPOSITORY"]
          run_id = os.environ["GITHUB_RUN_ID"]
          token = os.environ.get("GITHUB_TOKEN", "")

          url = f"https://api.github.com/repos/{repo}/actions/runs/{run_id}/artifacts?per_page=100"
          req = urllib.request.Request(url)
          req.add_header("Accept", "application/vnd.github+json")
          if token:
            req.add_header("Authorization", f"Bearer {token}")

          with urllib.request.urlopen(req, timeout=30) as resp:
            data = json.loads(resp.read().decode("utf-8", errors="replace"))

          names = {a.get("name", "") for a in data.get("artifacts", [])}
          has_test_results = "test-results" in names
          has_backend_logs = "backend-logs-e2e-tests" in names

          out_path = os.environ.get("GITHUB_OUTPUT")
          if out_path:
            with open(out_path, "a", encoding="utf-8") as f:
              f.write(f"has_test_results={'true' if has_test_results else 'false'}\n")
              f.write(f"has_backend_logs={'true' if has_backend_logs else 'false'}\n")
          PY

      - name: Download Playwright logs artifact
        if: ${{ steps.artifacts.outputs.has_test_results == 'true' }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: test-results

      - name: Download backend logs artifact
        if: ${{ steps.artifacts.outputs.has_backend_logs == 'true' }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: backend-logs-e2e-tests
          path: backend-logs-e2e-tests

      - name: Build payload.json
        shell: bash
        env:
          RUN_ID: ${{ github.run_id }}
          JOB_NAME: e2e-tests
          TIMESTAMP: ${{ github.event.head_commit.timestamp || github.event.pull_request.updated_at || '' }}
          BRANCH: ${{ github.ref_name }}
          COMMIT: ${{ github.sha }}
          STATUS: ${{ needs.e2e-tests.result }}
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          def read_text(path: str) -> str:
              p = Path(path)
              if not p.exists():
                  return ""
              try:
                  return p.read_text(encoding="utf-8", errors="replace")
              except Exception:
                  return ""

          payload = {
              "run_id": int(os.environ.get("RUN_ID", "0") or 0),
              "job_name": os.environ.get("JOB_NAME", "e2e-tests"),
              "timestamp": os.environ.get("TIMESTAMP", "") or "",
              "playwright_log": read_text("test-results/logs/playwright.log"),
              "backend_log": read_text("backend-logs-e2e-tests/django/logs/system/ci.log"),
              "branch": os.environ.get("BRANCH", ""),
              "commit": os.environ.get("COMMIT", ""),
              "status": os.environ.get("STATUS", ""),
          }

          with open("payload.json", "w", encoding="utf-8") as f:
              json.dump(payload, f, ensure_ascii=False)
          PY

      - name: POST logs to cloud agent
        shell: bash
        env:
          AGENT_TOKEN: ${{ secrets.AGENT_TOKEN }}
        run: |
          set -euo pipefail

          CLOUD_AGENT_URL="https://praxi-app.vercel.app/api/ci/logs"

          if [ -z "${AGENT_TOKEN:-}" ]; then
            echo "AGENT_TOKEN is not available; skipping log upload."
            exit 0
          fi

          if echo "$CLOUD_AGENT_URL" | grep -q "<YOUR-VERCEL-URL>"; then
            echo "CLOUD_AGENT_URL is still the default placeholder; skipping log upload."
            exit 0
          fi

          curl -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${AGENT_TOKEN}" \
            -d @payload.json \
            "$CLOUD_AGENT_URL" || {
              code=$?
              echo "Log upload failed (curl exit code: ${code}); continuing without failing the workflow."
              exit 0
            }

  django-postgres-deploy-check:
    name: Django + Postgres + Deployment Message
    runs-on: ubuntu-latest
    needs:
      - auth-validator
      - seed-orchestrator
      - page-smoke
      - e2e-tests
      - flaky-classifier
      - selector-auditor
      - ci-dashboard-agent
      - publish-dashboard
      - send-ci-logs
    if: ${{ false }}
    env:
      POSTGRES_USER: praxi
      POSTGRES_PASSWORD: praxi
      POSTGRES_DB: praxi
      POSTGRES_HOST: 127.0.0.1
      DJANGO_SETTINGS_MODULE: praxi_backend.settings.dev
      E2E_USER: e2e_ci
      E2E_PASSWORD: test1234
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: praxi
          POSTGRES_PASSWORD: praxi
          POSTGRES_DB: praxi
        ports:
          - 5432
        options: >-
          --health-cmd="pg_isready -h 127.0.0.1 -U praxi -d praxi"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=30
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'
          cache: 'npm'

      - name: Install PostgreSQL client
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Configure Postgres env
        shell: bash
        run: |
          set -euo pipefail
          echo "POSTGRES_PORT=${{ job.services.postgres.ports[5432] }}" >> "$GITHUB_ENV"
          echo "DATABASE_URL=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${{ job.services.postgres.ports[5432] }}/${POSTGRES_DB}" >> "$GITHUB_ENV"

      - name: Wait for PostgreSQL (max 90s)
        shell: bash
        run: |
          set -euo pipefail
          ready=false
          for i in {1..90}; do
            if pg_isready -h "${POSTGRES_HOST}" -p "${POSTGRES_PORT}" -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" >/dev/null 2>&1; then
              ready=true
              echo "Postgres is ready after ${i}s"
              break
            fi
            sleep 1
          done
          if [ "$ready" != "true" ]; then
            echo "Postgres not ready after 90 seconds" >&2
            exit 1
          fi

      - name: Install Django dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r django/requirements.txt

      - name: Install test dependencies
        shell: bash
        run: |
          set -euo pipefail
          npm ci
          npx playwright install --with-deps chromium

      - name: Run Django migrations
        shell: bash
        run: |
          set -euo pipefail
          python django/manage.py migrate

      - name: Seed database
        shell: bash
        run: |
          set -euo pipefail
          commands="$(python django/manage.py help | awk '/^    [a-z_][a-z0-9_]*$/{print $1}')"

          if echo "$commands" | grep -Fxq 'seed_test_data'; then
            python django/manage.py seed_test_data
          elif echo "$commands" | grep -Fxq 'create_test_data'; then
            python django/manage.py create_test_data
          elif echo "$commands" | grep -Fxq 'seed'; then
            python django/manage.py seed
          else
            echo "No supported seed command found (expected: seed_test_data, create_test_data, or seed)." >&2
            python django/manage.py help
            exit 1
          fi

      - name: Ensure E2E login user
        shell: bash
        run: |
          set -euo pipefail
          python django/manage.py shell -c "
          from praxi_backend.core.models import User

          user, _ = User.objects.get_or_create(
              username='e2e_ci',
              defaults={
                  'email': 'e2e_ci@seed.local',
                  'is_active': True,
                  'is_staff': True,
              },
          )
          user.is_active = True
          user.is_staff = True
          user.set_password('test1234')
          user.save()
          print('✅ ensured e2e_ci credentials')
          "

      - name: Run Django unit tests
        shell: bash
        run: |
          set -euo pipefail
          python django/manage.py test

      - name: Start Django for E2E
        shell: bash
        run: |
          set -euo pipefail
          nohup python django/manage.py runserver 0.0.0.0:8000 > django-server.log 2>&1 &

      - name: Wait for Django health endpoint
        shell: bash
        run: |
          set -euo pipefail
          ready=false
          for i in {1..60}; do
            if curl -fsS http://127.0.0.1:8000/api/health/ >/dev/null 2>&1; then
              ready=true
              echo "Django is reachable after ${i}s"
              break
            fi
            sleep 1
          done
          if [ "$ready" != "true" ]; then
            echo "Django did not become reachable within 60 seconds" >&2
            exit 1
          fi

      - name: Run E2E tests
        shell: bash
        run: |
          set -euo pipefail
          npx playwright test

      - name: Successful deployment message
        shell: bash
        run: |
          echo "https://praxi-app.vercel.app/"
